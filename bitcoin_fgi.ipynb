{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Fear & Greed Index\n",
    "***\n",
    "\n",
    "### Introduction\n",
    "***\n",
    "This is an attempt to create a sentiment index for Bitcoin. This sentiment index can be used for the purpose of trading into bitcoins and also as an indicator of overall mood. I have broadly divided the components of this index in two categories as follows.\n",
    "\n",
    "**Market Sentiment**\n",
    " - Momentum\n",
    " - Implied Volatility (VIX)\n",
    " - Price / MA\n",
    " - Simulated Price (using Geometric Brownian Motion)\n",
    " \n",
    "**Social Sentiment**\n",
    " - Google search trend\n",
    " - News articles\n",
    " - Reddit posts\n",
    "\n",
    "### Methoodology\n",
    "***\n",
    "\n",
    "Data points that are used for creating this index are from 1 May 2018 to 31 May 2018. This project is only for PoC purpose. The limitation of the dataset is majorly due to non availability of historical social sentiment data with free api's. The methodology used to compute various factors is stated below.\n",
    "\n",
    "- **Momentum**: Momentum is calculated as\n",
    "$$momentum = \\frac{90dEMA - 30dEMA}{90dEMA}$$\n",
    "\n",
    "\n",
    "- **Implied Volatility**: Volatility Index is calculated using forecasted volatility using GARCH(1,1) model. Forecast for next 24 periods of volatility is made and calculated as $$\\left ( \\frac{VIX_t}{100} \\right )^2 = \\frac{1}{n}\\sum_{k=1}^{n}E_{t}^{Q}\\left [ \\tilde{h}_{t+\\frac{\\tau_0 k}{n}} \\right ]$$\n",
    "\n",
    "  Refrence: Hao, J., & Zhang, J. E. (2013). GARCH option pricing models, the CBOE VIX, and variance risk premium. Journal of Financial Econometrics, 11(3), 556-580.\n",
    "\n",
    "\n",
    "- **Price / 125d MA**\n",
    "\n",
    "\n",
    "- **Google Search Trend**: Interest over time from google trends for the keyword 'bitcoin'\n",
    "\n",
    "\n",
    "- **News**: Sentiment analysis using vaderSentiment api of news articles with 'bitcoin' keyword in their title\n",
    "\n",
    "\n",
    "- **Reddit**: Top posts titles in subreddit r/bitcoin are captured and sentiment analysis using vaderSentiment is performed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and resampling\n",
    "\n",
    " - Original bitcoin price data is of 30min frequency, but needs to be resampled to 60min frequency as the social sentiment data is only available at 60min frequency\n",
    " - Series is extracted for a period more than required so as to factor in for moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bitcoin.csv', sep = '\\t')\n",
    "df.Timestamp = pd.to_datetime(df.Timestamp) # convert timestamp to datetime format\n",
    "df.replace(to_replace='â€”', value = '', inplace=True) # replace - values with blanks\n",
    "df.set_index(df.Timestamp,drop=True,inplace=True) # set timestamp as index\n",
    "df.drop(labels = 'Timestamp', axis = 1, inplace=True) # drop timestamp column\n",
    "\n",
    "# convert data to numeric\n",
    "df[['Open','High','Low','Volume (BTC)','Volume (Currency)','Weighted Price','Close']] = df[['Open','High','Low','Volume (BTC)','Volume (Currency)','Weighted Price','Close']].apply(pd.to_numeric)\n",
    "\n",
    "df.fillna(method='ffill',inplace=True) # forward fill na values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Bitcoin Prices')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ectracting the data as required, additional 125 periods are added in begining to account for moving average\n",
    "df2 = df.ix[datetime.date(year=2018,month=4,day=25):datetime.date(year=2018,month=5,day=31)].copy()\n",
    "\n",
    "# resample the dataframe to a 60min frequency\n",
    "dfh  = pd.DataFrame()\n",
    "dfh['open'] = df2.Open.resample('60Min', base = 30).last()\n",
    "dfh['high'] = df2.High.resample('60Min', base = 30).last()\n",
    "dfh['low'] = df2.Low.resample('60Min', base = 30).last()\n",
    "dfh['close'] = df2.Close.resample('60Min', base = 30).last()\n",
    "dfh['volume_btc'] = df2['Volume (BTC)'].resample('60Min', base = 30).last()\n",
    "dfh['volume_currency'] = df2['Volume (Currency)'].resample('60Min', base = 30).last()\n",
    "dfh['wtd_price'] = df2['Weighted Price'].resample('60Min', base = 30).last()\n",
    "\n",
    "# plot the bitcoin close price time series\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(dfh.index, dfh.close)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Bitcoin Prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cchopade/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# get list of all files in the news data folder\n",
    "files = glob.glob(\"/home/cchopade/crypto_hackathon/data/news/*.txt\")\n",
    "\n",
    "# initialize vaderSentiment object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# create empty dataframe to store data\n",
    "news_data = pd.DataFrame(columns = ['published','title','text','neg','neu','pos','compound'])\n",
    "\n",
    "# loop through each file, parse text, perform sentiment analysis and store to dataframe\n",
    "for file in files:\n",
    "    with open(file) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "\n",
    "\n",
    "    # create a blank dictionary to convert the data in a pandas dataframe\n",
    "    news_dict = { \"published\":[],\n",
    "                    \"title\":[],\n",
    "                    \"text\":[], \"neg\":[],\n",
    "                    \"neu\": [],\n",
    "                    \"pos\": [],\n",
    "                    \"compound\":[]}\n",
    "\n",
    "    for news in data['posts']:\n",
    "        news_dict[\"published\"].append(news['published'])\n",
    "        news_dict[\"title\"].append(news['title'])\n",
    "        news_dict[\"text\"].append(news['text'])\n",
    "        vs = analyzer.polarity_scores(news['text'])\n",
    "        news_dict[\"neg\"].append(vs['neg'])\n",
    "        news_dict[\"neu\"].append(vs['neu'])\n",
    "        news_dict[\"pos\"].append(vs['pos'])\n",
    "        news_dict[\"compound\"].append(vs['compound'])\n",
    "\n",
    "    \n",
    "    news_data = news_data.append(pd.DataFrame(news_dict),ignore_index=True)\n",
    "\n",
    "news_data.to_csv('data/news_analysis.csv') # save processed data to csv for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all files in the news data folder\n",
    "files = glob.glob(\"/home/cchopade/crypto_hackathon/data/google_news/*.txt\")\n",
    "\n",
    "# initialize vaderSentiment object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# create empty dataframe to store data\n",
    "news_data = pd.DataFrame(columns = ['published','title','text','neg','neu','pos','compound'])\n",
    "\n",
    "# loop through each file, parse text, perform sentiment analysis and store to dataframe\n",
    "for file in files:\n",
    "    with open(file) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "\n",
    "\n",
    "    # create a blank dictionary to convert the data in a pandas dataframe\n",
    "    news_dict = { \"published\":[],\n",
    "                    \"title\":[],\n",
    "                    \"text\":[], \"neg\":[],\n",
    "                    \"neu\": [],\n",
    "                    \"pos\": [],\n",
    "                    \"compound\":[]}\n",
    "\n",
    "    for news in data['articles']:\n",
    "        news_dict[\"published\"].append(news['publishedAt'])\n",
    "        news_dict[\"title\"].append(news['title'])\n",
    "        news_dict[\"text\"].append(news['description'])\n",
    "        if news['description'] == None:\n",
    "            vs = analyzer.polarity_scores(news['title'])\n",
    "        else:\n",
    "            vs = analyzer.polarity_scores(news['description'])\n",
    "        news_dict[\"neg\"].append(vs['neg'])\n",
    "        news_dict[\"neu\"].append(vs['neu'])\n",
    "        news_dict[\"pos\"].append(vs['pos'])\n",
    "        news_dict[\"compound\"].append(vs['compound'])\n",
    "\n",
    "    \n",
    "    news_data = news_data.append(pd.DataFrame(news_dict),ignore_index=True)\n",
    "\n",
    "news_data.to_csv('data/google_news_analysis.csv') # save processed data to csv for future use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
